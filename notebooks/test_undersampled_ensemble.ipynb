{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advance-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.utils.wandb_utils import get_config\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"kealexanderwang\"\n",
    "project = \"importance-reweighing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "emerging-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_names = [\n",
    "    \"hopeful-jazz-53\",\n",
    "    \"summer-bee-52\",\n",
    "    \"peachy-universe-51\",\n",
    "    \"worthy-star-50\",\n",
    "    \"peachy-hill-49\",\n",
    "]\n",
    "\n",
    "query = {\"displayName\": {\"$in\": run_names}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "superb-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_to_omegaconf(config: dict):\n",
    "    from omegaconf import OmegaConf\n",
    "    \n",
    "    keys, values = zip(*config.items())\n",
    "    \n",
    "    # convert from keys that look like \"datamodules/batch_size\" into \"datamodules.batch_size\"\n",
    "    dot_keys = [key.replace(\"/\", \".\") for key in keys]\n",
    "    \n",
    "    # convert \"None\" strings into \"null\" for OmegaConf to parse it as a None object\n",
    "    new_values = [\"null\" if v == \"None\" else v for v in values]\n",
    "    \n",
    "    dot_list = [f\"{k}={v}\" for k,v in zip(dot_keys, new_values)]\n",
    "    omega_conf = OmegaConf.from_dotlist(dot_list)\n",
    "    return omega_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deluxe-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def init_model(name_config: Tuple[str, dict], epoch):\n",
    "    \n",
    "    name, config = name_config\n",
    "    config = config_to_omegaconf(config)\n",
    "    run_dir = config[\"run_dir\"]\n",
    "    ckpt_path = f\"{run_dir}/checkpoints/epoch={epoch}.ckpt\"\n",
    "    \n",
    "    config.trainer.gpus = 0  # don't use GPU for test time\n",
    "    from src.train import hydra_init\n",
    "    hydra_objs = hydra_init(config)\n",
    "    \n",
    "    model = hydra_objs.model\n",
    "    import torch\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    \n",
    "    datamodule = hydra_objs.datamodule\n",
    "    datamodule.setup()\n",
    "    return model, datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wireless-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_configs = get_config(user=user, project=project, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surrounded-israeli",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.pl_models.imbalanced_classifier_model.ImbalancedClassifierModel'> initialized with unused kwargs: ['params_total', 'params_trainable', 'params_not_trainable']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/alex/miniconda3/envs/is/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.pl_models.imbalanced_classifier_model.ImbalancedClassifierModel'> initialized with unused kwargs: ['params_total', 'params_trainable', 'params_not_trainable']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.pl_models.imbalanced_classifier_model.ImbalancedClassifierModel'> initialized with unused kwargs: ['params_total', 'params_trainable', 'params_not_trainable']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.pl_models.imbalanced_classifier_model.ImbalancedClassifierModel'> initialized with unused kwargs: ['params_total', 'params_trainable', 'params_not_trainable']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.pl_models.imbalanced_classifier_model.ImbalancedClassifierModel'> initialized with unused kwargs: ['params_total', 'params_trainable', 'params_not_trainable']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model_datamodule_lst = [init_model(name_config, epoch=499) for name_config in name_configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chicken-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = model_datamodule_lst[0][1].val_dataset\n",
    "models = [m_d[0] for m_d in model_datamodule_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ranking-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_step(batch, models, method=\"majority\"):\n",
    "    \"\"\"Majority vote ensembling\"\"\"\n",
    "    import torch\n",
    "    loss_preds_y = [model.step(batch) for model in models]\n",
    "    _, logits_lst, preds_lst, _ = zip(*loss_preds_y)\n",
    "    if method == \"majority\":\n",
    "        ensemble_preds = torch.stack(preds_lst)\n",
    "        preds = torch.mode(ensemble_preds, axis=0).values\n",
    "    elif method == \"average\":\n",
    "        ensemble_logits = torch.stack(logits_lst)\n",
    "        ensemble_probs = torch.nn.functional.softmax(ensemble_logits, dim=-1)\n",
    "        average_prob = ensemble_probs.mean(0)\n",
    "        preds = torch.argmax(average_prob, dim=-1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "measured-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(val_dataset, batch_size=256)\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "for x, y in dataloader:\n",
    "    batch = x, y\n",
    "    y_pred = ensemble_step(batch, models, \"average\")\n",
    "    \n",
    "    y_trues.append(y)\n",
    "    y_preds.append(y_pred)\n",
    "    \n",
    "y_trues = torch.cat(y_trues)\n",
    "y_preds = torch.cat(y_preds)\n",
    "\n",
    "val_acc = (y_trues == y_preds).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "junior-boating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7225000262260437"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "matched-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(val_dataset, batch_size=256)\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "for x, y in dataloader:\n",
    "    batch = x, y\n",
    "    y_pred = ensemble_step(batch, models, \"majority\")\n",
    "    \n",
    "    y_trues.append(y)\n",
    "    y_preds.append(y_pred)\n",
    "    \n",
    "y_trues = torch.cat(y_trues)\n",
    "y_preds = torch.cat(y_preds)\n",
    "\n",
    "val_acc = (y_trues == y_preds).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "consolidated-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7210000157356262"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-signal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

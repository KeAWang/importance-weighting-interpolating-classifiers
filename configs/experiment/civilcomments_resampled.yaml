# @package _global_
# settings from https://github.com/p-lambda/wilds/blob/e95bba8408aff524b48b96a4e7648df72773ad60/examples/configs/datasets.py#L85

defaults:
    - /datamodule: civilcomments_datamodule.yaml
    - /model: imbalanced_classifier_model.yaml
    - /optimizer: adamw.yaml
    - /architecture: distilbert_net.yaml                 
    - /loss_fn: cross_entropy.yaml
    - /lr_scheduler: linear.yaml

logger:
    wandb:
        tags: ["civilcomments", "resampled"]

trainer:
    min_epochs: 1
    max_epochs: 5
    gradient_clip_val: 1.0

datamodule:
    wrapper_type: reweighted

    tokenizer:
        pretrained_model_name_or_path: ${architecture.model_name}

    batch_size: 16
    num_workers: 4
    pin_memory: True
    flatten_input: False
    train_sampler: weighted

optimizer:
    lr: 0.00001
    weight_decay: 0.01

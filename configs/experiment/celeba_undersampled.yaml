# @package _global_

defaults:
    - /datamodule: celeba_datamodule.yaml
    - /model: imbalanced_classifier_model.yaml
    - /optimizer: sgd.yaml                    
    - /architecture: res_net.yaml                 
    - /loss_fn: null

logger:
    wandb:
        tags: ["undersampled"]

trainer:
    min_epochs: 1
    max_epochs: 50
    limit_val_batches: 0.02


datamodule:
    wrapper_type: undersampled
    resolution: [224, 224]
    batch_size: 64
    num_workers: 4
    pin_memory: True
    flatten_input: False

optimizer:
    lr: 0.0004
    momentum: 0.9

architecture:
    arch: resnet50
    pretrained: True

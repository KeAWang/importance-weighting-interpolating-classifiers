{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torchvision \n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "#[TODO]Currently transform doesnt seem to do anything, so the transformations are carried out below. \n",
    "# Check and figure out why this doesnt work.\n",
    "transform = transforms.Compose(\n",
    "    [ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "#data_dir = Path(data_dir)\n",
    "data_dir = './data'\n",
    "train_data = torchvision.datasets.CIFAR10(root=data_dir, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root=data_dir, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_data.data = torch.FloatTensor(train_data.data)\n",
    "train_data.targets = torch.LongTensor(train_data.targets)\n",
    "test_data.data = torch.FloatTensor(test_data.data)\n",
    "test_data.targets = torch.LongTensor(test_data.targets)\n",
    "\n",
    "\n",
    "#Create a two-class-dataset of with just classes specified by the variable classes\n",
    "class_skew = 5\n",
    "classes = [3,5]\n",
    "reduction_factor = 5\n",
    "\n",
    "#Indices for the data with labels either of the classes\n",
    "idx_class_one = torch.BoolTensor([x== classes[0] for i,x in enumerate(train_data.targets)])\n",
    "idx_class_two = torch.BoolTensor([x== classes[1] for i,x in enumerate(train_data.targets)])\n",
    "\n",
    "\n",
    "#Sub_subsample to get reduce the second class examples by a factor of class_skew*reduction_factor\n",
    "indices_for_class_two = [i for i, x in enumerate(idx_class_two) if x]\n",
    "subsampled_indices = (random.sample(indices_for_class_two, int(len(indices_for_class_two)/(class_skew*reduction_factor))))\n",
    "for i in range(len(idx_class_two)):\n",
    "    if i not in subsampled_indices:\n",
    "         idx_class_two[i] = False\n",
    "#Sub_subsample to get reduce the first class examples by a factor of reduction_factor        \n",
    "indices_for_class_one = [i for i, x in enumerate(idx_class_one) if x]\n",
    "subsampled_indices = (random.sample(indices_for_class_one, int(len(indices_for_class_one)/(reduction_factor))))\n",
    "for i in range(len(idx_class_one)):\n",
    "    if i not in subsampled_indices:\n",
    "        idx_class_one[i] = False\n",
    "\n",
    "print('Number of samples in class one',sum(idx_class_one).item())\n",
    "print('Number of samples in class two',sum(idx_class_two).item())\n",
    "idx = torch.logical_or(idx_class_one,idx_class_two)\n",
    "\n",
    "#Training data\n",
    "train_data.targets = train_data.targets[idx]\n",
    "#print('Length of train_data', train_data.targets.size())\n",
    "#Converting classes to 0 and 1\n",
    "idx_class_one = torch.BoolTensor([x== classes[0] for i,x in enumerate(train_data.targets)])\n",
    "idx_class_two = torch.BoolTensor([x== classes[1] for i,x in enumerate(train_data.targets)])\n",
    "train_data.targets[idx_class_one] = (train_data.targets[idx_class_one]/classes[0]-1).type(torch.LongTensor)\n",
    "train_data.targets[idx_class_two] = (train_data.targets[idx_class_two]/classes[1]).type(torch.LongTensor)\n",
    "train_data.targets = train_data.targets.tolist()\n",
    "train_data.targets = [int(item) for item in train_data.targets]\n",
    "train_data.data = train_data.data[idx].numpy().astype(np.uint8)\n",
    "print('Total number of training samples',len(train_data.targets))\n",
    "#print(train_data.data[0].dtype)\n",
    "\n",
    "#batch_size = 16\n",
    "\n",
    "#Test data\n",
    "#Indices for the data with labels either of the classes\n",
    "idx_class_one = torch.BoolTensor([x== classes[0] for i,x in enumerate(test_data.targets)])\n",
    "idx_class_two = torch.BoolTensor([x== classes[1] for i,x in enumerate(test_data.targets)])\n",
    "idx = torch.logical_or(idx_class_one,idx_class_two)\n",
    "\n",
    "#Test data\n",
    "test_data.targets = test_data.targets[idx]\n",
    "idx_class_one = torch.BoolTensor([x== classes[0] for i,x in enumerate(test_data.targets)])\n",
    "idx_class_two = torch.BoolTensor([x== classes[1] for i,x in enumerate(test_data.targets)])\n",
    "test_data.targets[idx_class_one] = (test_data.targets[idx_class_one]/classes[0]-1).type(torch.LongTensor)\n",
    "test_data.targets[idx_class_two] = (test_data.targets[idx_class_two]/classes[1]).type(torch.LongTensor)\n",
    "test_data.targets = test_data.targets.tolist()\n",
    "test_data.targets = [int(item) for item in test_data.targets]\n",
    "test_data.data = test_data.data[idx].numpy().astype(np.uint8)\n",
    "\n",
    "\n",
    "batch_size = len(train_data.targets)\n",
    "#trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                         # shuffle=True, num_workers=1)\n",
    "loaders = {'train' : torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1),\n",
    "'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "cnn = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc():\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            #pred_y = torch.sign(test_output)\n",
    "            #print(labels)\n",
    "            #print(pred_y)\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            \n",
    "    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "\n",
    "def train_acc():\n",
    "    # Train accuracy on the mode\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['train']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            #pred_y = torch.sign(test_output)\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            \n",
    "    print('Train Accuracy of the model on the 60000 train images: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyTailLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        super(PolyTailLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        margin_vals = ((logits[:,1]-logits[:,0])*(2*target-1)).view(-1)\n",
    "        return self.margin_fn(margin_vals)\n",
    "\n",
    "    def margin_fn(self, margin_vals):\n",
    "        indicator = margin_vals <= 1\n",
    "        scores = torch.zeros_like(margin_vals)\n",
    "        inv_part = torch.pow(margin_vals, -1*self.alpha)\n",
    "        logit_inner = -1*margin_vals\n",
    "        logit_part = (torch.log(torch.exp(logit_inner)+1))/math.log(1+math.exp(-1))\n",
    "        scores[indicator] = logit_part[indicator]\n",
    "        scores[~indicator] = inv_part[~indicator]\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5000], Loss: nan, Tr Acc: 0.8333, Tt Acc : 0.5000, Frac Pos : 0.0000, Test C0 : 1.0000, Test C1 : 0.0000, Difference : : 1.0000\n",
      "Epoch [10/5000], Loss: nan, Tr Acc: 0.8333, Tt Acc : 0.5000, Frac Pos : 0.0000, Test C0 : 1.0000, Test C1 : 0.0000, Difference : : 1.0000\n",
      "Epoch [15/5000], Loss: nan, Tr Acc: 0.8333, Tt Acc : 0.5000, Frac Pos : 0.0000, Test C0 : 1.0000, Test C1 : 0.0000, Difference : : 1.0000\n",
      "Epoch [20/5000], Loss: nan, Tr Acc: 0.8333, Tt Acc : 0.5000, Frac Pos : 0.0000, Test C0 : 1.0000, Test C1 : 0.0000, Difference : : 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-728ffef1641c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-728ffef1641c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, cnn, loaders)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtotal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m# gives batch data, normalize x when iterate train_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training parameters\n",
    "#Default parameters for full gradients, epochs = 1000, lr = 0.01\n",
    "#Default parameters for batch_size = 32, epochs = 1000, lr = 0.01\n",
    "#Default parameters for batch_size = 16, epochs = 1000, lr = 0.01\n",
    "num_epochs = 5000\n",
    "iw_factor = 100\n",
    "#loss_func = nn.CrossEntropyLoss(reduce=None, reduction='none')\n",
    "loss_func = PolyTailLoss(alpha=1)\n",
    "optimizer = optim.SGD(cnn.parameters(), lr = 0.5)\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    cnn.train()\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(loaders['train'],0):\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            images, labels = data\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            idx_class_1 = b_y == 1\n",
    "            weights = torch.ones_like(b_y, requires_grad=False, dtype=torch.float64)\n",
    "            weights[idx_class_1] = iw_factor*torch.ones_like(weights[idx_class_1])\n",
    "            weights = weights/iw_factor\n",
    "            output = cnn(b_x)\n",
    "            #loss = loss_func(output, b_y).mean()\n",
    "            #print(output.size())\n",
    "            #print(cnn(b_x).size())\n",
    "            #print(loss_func(output, b_y).size())\n",
    "            loss = torch.mean(loss_func(output, b_y)*weights)\n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            loss.backward()               \n",
    "            optimizer.step() \n",
    "            \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            cnn.eval()\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                correct_te = 0\n",
    "                total_te = 0\n",
    "                frac_pos = 0\n",
    "                correct_cl_0 = 0\n",
    "                total_cl_0 = 0\n",
    "                correct_cl_1 = 0\n",
    "                total_cl_1 = 0\n",
    "                for i, data in enumerate(loaders['train'],0):\n",
    "                    images, labels = data\n",
    "                    train_output = cnn(images)\n",
    "                    pred_y = torch.max(train_output, 1)[1].data.squeeze()\n",
    "                    correct += (pred_y == labels).sum().item() \n",
    "                    total += float(labels.size(0))\n",
    "                accuracy = correct/total\n",
    "                for i, data in enumerate(loaders['test'],0):\n",
    "                    images, labels = data\n",
    "                    test_output = cnn(images)\n",
    "                    pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "                    #Total test accuracy\n",
    "                    correct_te += (pred_y == labels).sum().item()\n",
    "                    total_te += float(labels.size(0))\n",
    "                    #fraction of labels predicted to be positive\n",
    "                    frac_pos += torch.sum(pred_y).item()\n",
    "                    #class_0_accuracy\n",
    "                    idx_cl_0 = labels == 0\n",
    "                    correct_cl_0 += (pred_y[idx_cl_0] == labels[idx_cl_0]).sum().item() \n",
    "                    total_cl_0 += float(labels[idx_cl_0].size(0))\n",
    "                    #class_1_accuracy\n",
    "                    idx_cl_1 = labels == 1\n",
    "                    correct_cl_1 += (pred_y[idx_cl_1] == labels[idx_cl_1]).sum().item() \n",
    "                    total_cl_1 += float(labels[idx_cl_1].size(0))\n",
    "            \n",
    "                test_accuracy = correct_te/total_te\n",
    "                fraction_pos = frac_pos/total_te\n",
    "                accuracy_cl_0 = correct_cl_0/total_cl_0\n",
    "                accuracy_cl_1 = correct_cl_1/total_cl_1\n",
    "                difference = abs(accuracy_cl_0-accuracy_cl_1)\n",
    "                \n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}, Tr Acc: {:,.4f}, Tt Acc : {:,.4f}, Frac Pos : {:,.4f}, Test C0 : {:,.4f}, Test C1 : {:,.4f}, Difference : : {:,.4f}' \n",
    "                   .format(epoch + 1, num_epochs,  iw_factor*loss.item(),accuracy, test_accuracy, fraction_pos, accuracy_cl_0,accuracy_cl_1,difference))\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
